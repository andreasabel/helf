\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{LFMTP'11} % Name of the event you are submitting to
% \usepackage{breakurl}             % Not needed if you use pdflatex only.


\input{mymacros}

\usepackage{proof}
\usepackage[all]{xy}



\title{A Lambda Term Representation Based on Linear Ordered Logic}
\author{Andreas Abel
\institute{
Theoretical Computer Science\\
Institut f\"ur Informatik\\
Ludwig-Maximilians-Universit\"at\\
M\"unchen, Germany}
\email{andreas.abel@ifi.lmu.de}
\and
Nicolai Kraus
\institute{
Functional Programming Laboratory\\
School of Computer Science\\
University of Nottingham\\
Nottingham, United Kingdom}
\email{ngk@cs.nott.ac.uk}
}
\def\titlerunning{A Lambda Term Representation Based on Linear Ordered Logic}
\def\authorrunning{Andreas Abel, Nicolai Kraus}
\begin{document}
\maketitle

\begin{abstract}
We introduce a nameless representation of lambda terms based on ordered logic. 
Information about number and places of variables bound by a lambda is available without examining the whole term, thus making it possible to drop unneeded substitutions early to avoid memory leaks.
% We describe an implementation of this and other representations as well as suggested evaluation algorithms. These implementations were tested in Haskell by using them for typechecking large dependently typed terms of the logical framework (LF). The different needs of time and space are documented and compared.\\
We also describe our implementation experiments and present some results.
\end{abstract}

\section{Introduction}

Beta reduction is an important part of evaluating in many functional programming languages, proof assistants and other formal systems. However, implementations often involve the risk of memory leaks and inefficiency. Here, we assume that all of our terms are well-typed and beta reduction is therefore strongly normalizing, so all we care about is efficiency. \\
A term representation always has to have a way to represent that a variable is bound by a lambda. For example, in the term $\LaA x {\ApA {\ApA a b} x}$ in basic syntax, the information about the connection of the $\la$ and the last variable is split: We have to look at both the $x$ and the $\la x$ in order to know what is going on. This may lead to some unnecessary difficulties. In contrast, the usage of de Bruijn indices makes it possible to remove the information from the $\la$ and concentrate them on the variable. Our goal is to do it the other way round: We want the whole information to be available at the $\la$.


To demonstrate the problem we want to deal with, we consider the term $(\LaA x {\LaA y {\ApA{\ApA a b} y}}) \sspace g \sspace f$ in standard syntax. 
If we want to get rid of the beta redexes, we could reduce it in the way shown below. By writing $t\multisubs {s_1} {x_1} {s_n} {x_n}$, we want to express that in the term $t$, each occurence of the variable $x_1$ ($x_2, \ldots, x_n$) has to be replaced by the term $s_1$ (resp. $s_2, \ldots, s_n$) simultaneously. Such a substitution list always applies only to the directly preceding term:
\[
\begin{array}{lr@{}l}
\shspace &(\LaA x {\LaA y {\ApA{\ApA a b} y}}) & \sspace g \sspace f \\ 
\shspace\re &(\LaA y {\ApA{\ApA a b} y}) & \sub g x \lspace f \\ 
\shspace\re &      (\ApA{\ApA a b} y) & \subs g x f y \\ 
\shspace\re &      \multicolumn 2 l {(a\sspace b)\subs g x f y \lspace y\subs g x f y} \\ 
\shspace\re &      \multicolumn 2 l {a\subs g x f y \lspace b\subs g x f y \lspace f} \\ 
\shspace\re &      \multicolumn 2 {c} {a \sspace b \sspace f}  \\ 
\end{array}
\]
Actually, the substitution $\sub g x$ could be dropped instantly and there is no need to apply the other substitution $\sub f y$ to the term $\ApA a b$. However, the algorithm used above does not have this information and this is a problem that many representations come along with. Motivated by this observation, we want to describe an alternative.

\section{Syntax}

% The idea is that the information which variable is bound by which lambda should neither be split (like in the standard representation) nor carried by the variable (de Bruijn indices). Instead, it should be available as soon as the lambda becomes visible.
Here, we only cover the core constructs of the lambda calculus, but we do not see any limitations for probably needed extensions. We first define ordered preterms, which are ordered terms if they satisfy a condition discussed below:
\[
\begin{array}{lllrll@{\qquad}}
\mathsf{ordered \ preterms}       & \ni & t,u & ::= & x & \mbox{free variable (named $x$)} \\
			                   &&& \mid & \ovar & \mbox{bound variable (nameless)} \\
			                   &&& \mid & \ApO t k u & \mbox{application} \\
			                   &&& \mid & \LaO {\vec k} t & \mbox{abstraction} \\
\end{array}
\]
\emph{Free variables} are denoted by their name like in the standard syntax. \emph{Bound variables}, however, are just denoted by a dot $\ovar$, which does not carry any information beside the fact that it is a bound variable. 
% This, for example, means that if $\left(\ApO \ovar 1 \ovar \right)$ is a subterm, it is not possible to tell whether we have two different variables or two times the same one without looking at the whole term.\footnote{However, the latter possibility could not be well-typed.} 
In the case of an \emph{application}, there is a first term and a second term as usual. 
Furthermore, the application carries an integer $k$ as an additional information that will be important for the evaluation process and is explained in the next paragraph.
%the number of dots $\ovar$ in the first term which are not bound by lambdas in the first term itself should be denoted by the integer $k$. % COMMENT - there is no reason anymore to prefer the second to the first term. It might be a good idea to use the first term instead!? I have changed it now.
%This will be important for the evaluation process. 
The most interesting part is the \emph{abstraction} $\LaO {\vec k} t$. The vector $\vec k = \ve{k_1, k_2, \ldots, k_n}$ is nothing else but a list of nonnegative  integers of length $n$. It determines which dots $\ovar$ are bound by the $\la$ in the following way: Consider all $\ovar$ in the term $t$ which are not bound in $t$ itself. Now, the first $k_1$ of these are not bound by the $\la$, the next one is, the following $k_2$ are again not bound and so on (see examples below). 

We denote the number of unbound $\ovar$ in an ordered preterm $t$ by $\freevars t$. Consequently, $\freevars \cdot$ is simply defined by 
\[
\begin{array}{cccc}
\freevars x = 0, & \freevars \ovar = 1, & \freevars {\ApO t k u} = \freevars {t} + \freevars{u}, & \freevars {\LaO {\ve {k_1, \ldots, k_n}} t} = \freevars t - n.
\end{array}
\]
%Note that in the case of $\ApO t k u$, we have $k = \freevars u$ by definition of $k$. \\
Now, an ordered preterm $u$ is an ordered term if each lambda abstraction $\LaO {\ve {k_1, \ldots, k_n}} t$ which is a sub-preterm of $u$ satisfies the condition $n + \sum_i k_i \leq \freevars t$. In other words, if a $\la$ in $u$ binds a variable, this variable must actually exist. In addition, each sub-preterm $\ApO t k u$ has to fulfil the condition $k = \freevars t$.\\
$t$ is called \emph{closed} if $\freevars t = 0$.
% From now on, we only handle terms and forget about invalid preterms.

Here are some examples of closed terms.
The $S$ combinator 
\[
\LaA x {\LaA y {\LaA z {\ApA x z \sspace \pa {\ApA y z}}}}
\]
would be written as 
\[\LaO {\ve 0} {\LaO {\ve 1} {\LaO {\ve{1,1}} {\ApO {\ApO \ovar 1 \ovar} 2 {\pa{\ApO \ovar 1 \ovar}}}}}.
\]
Moreover, the term 
\[
(\LaA x {\LaA y {\ApA{\ApA a b} y}}) \sspace g \sspace f
\]
from the very beginning would be represented as
\[
\ApO{\left(\ApO {\LaO{\emptyVec}{\LaO{\ve 0}{\ApO{\ApO{a}{0}{b}}{0}{\ovar}}}\right)}  0 f } 0 g
\]
(note that applications are still left-associative). Now, we can see that the first $\la$ does not bind anything as it is annotated with the empty vector $\emptyVec$, while this is less obvious when it is written as $\la x$.


\section{Values and Evaluation} \label{eval}

Before specifying values and evaluation formally, we want to give an example to demonstrate how the information carried by a lambda should be used and why we always have exactly the needed information. Suppose we have the term
\[
\left(\LaO {\ve 0} {\LaO {\ve 1} {\LaO {\ve{1,1}} {\ovar \oapp 1 \ovar \oapp 2 {\pa{\ovar \oapp 1 \ovar}}}}}\right) \sspace g \sspace f \sspace n, \\ 
\]
i.e. the $S$ combinator which is first applied to a constant $g$, then to $f$ and finally to $n$. We want to get rid of the beta redexes, so we start by eliminating the first one. The outermost $\la$ is decorated with the vector $\ve 0$ of length one. Now, the single variable bound by this $\la$ should be replaced by $g$, so we start a substitution list and insert a single $g$:
\[
\left(\LaO {\ve 1} {\LaO {\ve{1,1}} {\ovar \oapp 1 \ovar \oapp 2 {\pa{\ovar \oapp 1 \ovar}}}}\right) \left[ g \right] \lspace f \sspace n
\]
The first remaining $\la$ is $\la^{\ve 1}$, so it does not bind the first variable (which means, $g$ stays on the first place of the substitution list), but the second one. Consequently, we add an $f$ after the $g$:
\[
\left(\LaO {\ve{1,1}} {\ovar \oapp 1 \ovar \oapp 2 {\pa{\ovar \oapp 1 \ovar}}}\right)  \left[ g, f \right] \lspace n
\]
Now the situation becomes more interesting. The only remaining $\la$ is now decorated with the vector $\ve{1,1}$, so one $n$ has to be inserted after the first entry (which is $g$), another one must be placed after the following entry:
\[
\left(\ovar \oapp 1 \ovar \oapp 2 {\pa{\ovar \oapp 1 \ovar}}\right)  \left[ g, n, f, n \right]
\]
Finally, all $\la$ are eliminated. The applications' indices tell us how the substitution list should be divided between the terms:
\[
\left(\ovar \oapp 1 \ovar\right)\left[ g, n \right] \lspace \left(\ovar \oapp 1 \ovar\right) \left[ f, n \right]
% \left(\ovar \oapp 1 \ovar\right)\left[ g, n \right] \lspace \oapp 0 \lspace \left(\ovar \oapp 1 \ovar\right) \left[ f, n \right]
\]
Same step once more:
\[
\ovar[g]  \lspace \ovar[n]  \lspace \left(\ovar[f]  \lspace \ovar[n]\right)
\]
The only thing left to be done is to apply the substitutions in the obvious way:
\[
g \sspace n  \sspace (f \sspace n)
\]
Here, evaluation naturally leads to a term in beta normal form. This will not always be the case: as an example, if we had tried to evaluate the above term without the $n$ (i.e. $S \oapp 0 f \oapp 0 g$), we would have got stuck at $\left(\LaO {\ve{1,1}} {\ovar \oapp 1 \ovar \oapp 2 {\pa{\ovar \oapp 1 \ovar}}}\right)  \left[ g, f \right]$. On the other hand, this also would have been satisfactory as it would have shown that the term's normal form is an abstraction. % TODO give reason why this is enough

Consequently, we define values (the result of evaluation) in the following way:

\[ 
\begin{array}{lllrll@{\qquad}}
\mathsf{values}       & \ni & v,w & ::= & x \sspace \vec v & \mbox{large application} \\ 
% \noalign{\medskip}
			                   &&& \mid & \Val {\vec k} t {\vec v} & \mbox{closure} \\ 
\end{array}
\]
% \[
% \mathsf{values} \ni v, w ::= x \, \vec v \ \mid \ \ClosO{\vec k}{t}{}{\vec v}
% \]
The \emph{large application} consists of a variable $x$ which is applied to a vector $\ve{v_1, v_2, \ldots, v_m}$ of values. It is to be read as a left-associative application, i.e. as $\pa{\pa{h \, v_1} v_2 \ldots } v_m$. 
Note that it is not necessarily ``large''. Quite the contrary, it often only consists of the head (and the vector of values is empty).\\
A \emph{closure} $\Val {\vec k} t {\vec v}$ is the result of an evaluation process, if the corresponding beta normal form of the term just does not start with a free variable. The main part, $\LaO {\vec k} t$, is nothing other than a lambda abstraction in the syntax of ordered terms.
% ($t \in \mathsf{Ordered\,Terms}$). % TODO sollten offene terme wirklich terme sein?! vermutlich schon
Here, we need the substitution list $\vec v$ (which is simply a list of values) that satisfies $\length {\vec v} = \freevars{\LaO {\vec k} t}$. % as there might be unbound $\ovar$ in $\LaO {\vec k} t$. 
The idea is that the $i^{th}$ unbound $\ovar$ is to be replaced by $v_i$.  These substitution lists have already been used in the example above.


At this point, we want to introduce a notation for inserting a single item multiple times into a list. More precisely, if $\vec v = [v_1, v_2, \ldots, v_m]$ is a list (e.g. of values), $\vec k = [k_1, k_2, \ldots, k_n]$ is a vector (i.e. also a list) of  nonnegative integeres satisfying $\sum_{i=1}^n k_i \leq m$ and $w$ is a single item (value), we write $\multiinsert {\vec v} {\vec k} {w}$  for the list that is constructed by inserting $w$ at each of the positions $k_1, k_1 + k_2, \ldots, \sum_{i=1}^n k_i$ into $\vec v$, i.e. for the list $[v_1, v_2, \ldots, v_{k_1}, w, v_{k_1 + 1}, \ldots, v_{k_1 + k_2}, w, v_{k_1 + k_2 + 1}, \ldots, v_m]$ (of course, it is possible that $\multiinsert {\vec v} {\vec k} {w}$ starts or ends with $w$).


Now, we are able to define the evaluation function $\ev {\cdot} {\cdot}$ which takes an ordered term $t$ as well as an ordered substitution list $\vec v$ and returns a value. The tuple must always satisfy the condition $\freevars t = \length t$. In other words, the list carries neither too less nor redundant information.\\
At the start of the evaluation, the ordered substitution list is empty. \\
Additionally, we specify the application $\cdot \ap \cdot$ of two values, which also returns a value and does not need anything else.

\[ 
\begin{array}{llll}
& \ev x {\emptyVec} & = & x \\ \noalign{\medskip}
& \ev \ovar {\ve{v_1}} & = & v_1 \\  \noalign{\medskip}
& \ev {t \oapp k u} {\ve{v_1, \ldots, v_n}} & = & {\ev t {\ve{v_1, \ldots, v_{n-k}}}} \ap {\ev u {\ve{v_{n-k+1}, \ldots, v_n}}} \\  \noalign{\medskip}
& \ev {\LaO {\vec k} t}  {\vec v} & = & \Val {\vec k} t {\vec v} \\  
\\ 
& \pa{h \sspace \vec v} \ap w & = & h \sspace \ve{\vec v, w} 
\\ \noalign{\medskip}
& \Val{\vec k} t {\vec v}   \ap w & = & \ev t {\multiinsert{\vec v}{\vec k}{w}}
%& \Val {\vec k} t {\vec v}    \ap  w & = & \ev t {\vec {v'}}   \\
%&& 
%			  \multicolumn 2 l{
%			  \begin{array}{llcl}
%			  \mbox{where } & \vec v & = & \ve{v_1, \ldots, v_n} \\
%			                & \vec {v'} & = & \ve{v_1, \ldots, v_{k_1}, w, v_{k_1+1}, \ldots, v_{k_1+k_2}, w, \ldots }
%			  \end{array}
%			  }
\end{array}
\]
First, if we want to evaluate a free variable, the substitution list must be empty because of the invariant mentioned above. 
Second, in the case of a $\ovar$, the ordered list must have exactly one entry. This entry is the result of the evaluation. 
If we evaluate an application, we evaluate the left and the right term. The application's index enables us to split the substitution list at the right position. Then, we have to apply the first result to the second. 
Surprisingly, evaluating an abstraction is very simple. We just need to keep the substitutions to build a closure. \\
If we want to apply a large application to a value $w$, we just append $w$ to the vector of values (we write $\ve{\vec v, w}$ for $\ve{v_1, \ldots, v_n, w}$). 
The case of a closure $\Val {\vec k} t {\vec v}$ is less simple. $\vec k$ determines at which positions $w$ should be inserted in the ordered substitution list $\vec v$: The new list $\vec {v'}$ is build by inserting $w$ after the first $k_1$ values, after the next $k_2$ values and so on. In total, $w$ is used $\length {\vec k}$ times. Then, $t$ is evaluated.

% TODO THE WHOLE multiset THING IS unnecessary!

\section{Parsing and Printing}

In this section, we define how terms in normal syntax are translated into our ordered syntax (Parsing) and vice versa (Printing). 
To specify this, we need some notation. 
First of all, we write $\x$ for the set of variable names we want to use and $\te$ for the set of lambda terms in normal syntax (i.e. $\x \subset \te$, furthermore, $x \in \x$ together with $t, u \in \te$ implies $\ApA t u \in \te$ and $\LaA x t \in \te$). Additionally, $\ot$ is the set of terms in our ordered syntax defined above, $\otc$ the subset of closed ordered terms and $\va$ the set of values (defined in the previous section).
Moreover, we write $\xl$ for the set of lists of variable names and $\vl$ for the set of lists of values. 
\\
For each set $\Gamma$ of variable names ($\Gamma \subseteq \x$), we denote the set of lists of elements of $\Gamma$ by $\gl$. 
% We will often allow $\Gamma$ to be a finite multiset, i.e. a finite set that can contain each element more than once. The according notion of union $\uplus$ satisfies $\Gamma \uplus \{z\} \not= \Gamma$. 
\\
By $\ot \otimes \xl$ (resp. $\ot \otimes \vl$, $\ot \otimes \gl$) we mean the subset $\{(t, \vec x) \ | \ \freevars t = \length {\vec x} \}$ of $\ot \times \xl$ (and analogous for $\vl$ or $\gl$ instead of $\xl$).
\\
\begin{defin}
For each finite %multiset 
set $\Gamma$ of variable names, we define the relation
$\parse \cdot \Gamma \cdot \ \subset \  \te \times (\ot \times \xl)$.
The intuition is that $\parse M \Gamma (u, \vec x)$ (or simply $\parse M \Gamma {u \vec x}$) means: $M$ is a term that corresponds to the ordered term $u$, where unbound $\ovar$ are replaced by the variables in the list $\vec x$ and those variables are exactly the ones occuring in $\Gamma$:
\begin{gather*}
\infru{x \in \Gamma}{\parse x \Gamma {\ovar \ve x}}
\qquad
\qquad
\infru{x \not\in \Gamma}{\parse x \Gamma {x \emptyVec}}
\qquad
\qquad
\infru{ {\parse M \Gamma {t \vec x}} \qquad {\parse N \Gamma {u \vec y}} \qquad {\length{\vec x} = k} } {\parse {MN} {\Gamma} {(\ApO t k u) [\vec x, \vec y]} } \\
%\infru { {\parse M { \Gamma \uplus \{x\} } {t \ve{ \vec{x_1}, z, \vec{x_2}, z, \ldots, z, \vec{x_{n+1}}}}} 
%          \qquad 
%          k_i = \length{\vec {x_i}} 
%          \qquad 
%          {\vec x = \ve{\vec{x_1}, \vec{x_2}, \ldots, \vec{x_{n+1}}}} 
%          \qquad 
%          z \not\in \vec x 
%          } 
%          { \parse {\LaA z M} {\Gamma} {(\LaO {\ve{k_1, k_2, \ldots, k_n}} t) \ \vec x} } \\
\infru{ 
         {\parse M { \Gamma \uplus \{z\} } {       t \multiinsert{\vec x}{\vec k}{z}   }} 
          \qquad 
          z \not\in \vec x  }
          {\parse {\LaA z M} {\Gamma} {(\LaO {\vec{k}} t) \ \vec x}}
\end{gather*}
\end{defin}
First, it is important to notice that $\parse M \Gamma (u, \vec x)$ implies that each variable occuring in $\vec x$ is contained in $\Gamma$. This can be shown by induction on $M$ (simultaneously for all sets $\Gamma$). \\
By the same argument, one can see that (for each $M$ and $\Gamma$) there exists a unique tupel $(u, \vec x)$ satisfying $\parse M \Gamma {u  \vec x}$, so we can consider $\parse \cdot \Gamma \cdot$ a function $\te \rightarrow \ot \times \gl$. In the same way, we notice that $\parse M \Gamma {u  \vec x}$ always implies $\freevars u = \length {\vec x}$. \\
% By applying the function $\parse \cdot {\emptySet} \cdot$, we can transform a term from normal syntax to ordered syntax. \\
This also works the other way round. For each $\Gamma$ and each tupel $(u, \vec x) \in \te \otimes \gl$, there is (by induction on $u$) a term $M \in \te$ satisfying $\parse M \Gamma {(u, \vec x)}$. Moreover, this term $M$ is unique up to alpha equivalence. So, $\parse \cdot \Gamma \cdot$ is actually a bijection between $\te / \alpha$ (the set of equivalence classes of terms) and $\ot \otimes \gl$. The inference rules above show how to apply this bijection or its inverse to a term or a tupel (in the last rule, any variable satisfying the condition can be choosen for $z$), so we have (computable) functions $\parseFun \Gamma : \te / \alpha \rightarrow \ot \otimes \gl$ and $\parseFun \Gamma ^{-1}$. 
\\
Choosing $\Gamma = \emptySet$, we get bijections $\te \leftrightarrow \otc \otimes {\vec \emptySet}$. As $\vec \emptySet$ is only inhabited by the empty vector $\emptyVec$, we naturally get the parse function $\parseFunE$ which maps $\te$ bijectively on $\otc$.


%Choosing $\Gamma = \emptySet$, we get the special cases $\parseFun \emptySet$ and $\parseFun \emptySet ^{-1}$, which are bijections between $\te$ and $\otc$. This also explaines how one representation can be transformed into the other.

The above construction also gives us function $\ot \otimes \xl \rightarrow \te$, but this is not enough: We want to transform the (more general) elements of $\ot \otimes \vl$ as well as values in $\va$ into basic terms $\te$:

\begin{defin}
We define the two printing functions $\prE : \ot \otimes \vl \rightarrow \te / \alpha$ and $\prValE : \va \rightarrow \te / \alpha$ simultaneously by recursion on the structure:
\[
\begin{array}{lcl}
\pr{x}{\emptyVec} & = & x \\
\pr{\ovar}{[v]} & = & \prVal v \\
% \pr{t \oapp k u}{\vec v} = \ApA {\pr {t}{[v_1, \ldots, v_k]}  }  {\pr {u}{[v_{k+1}, \ldots, v_n]}}
\pr{t \oapp k u}{\vec v} & = & \ApA {\pr {t}{\vec{v_{start}}}  }  {\quad \pr {u}{\vec{v_{rest}}}} \\
&& \mbox{(split $\vec v$ at position $k$ to get $\vec{v_{start}}$ and $\vec{v_{rest}}$)} \\
% \pr{\LaO {k_1, \ldots, k_m} t}{[v_1, v_2, \ldots, v_n]} & = & \LaA z {\pr {t} {v_1, \ldots, v_{k_1}, z, v_{k_1+1}, \ldots, }}   \\
\pr{\LaO {\vec k} t}{\vec v} & = & \LaA z {\pr {t} {  \multiinsert{\vec v}{\vec k}{z}   }}   \\
\medskip
&& \mbox{where $z$ is any variable that does not occur freely in $t$ or $\vec v$ } \\
% && \mbox{$\vec w$ is constructed by taking $\vec v$ and inserting $z$ at position $k_1, k_1+k_2, \ldots$ just like} \\ 
% && \mbox{in the premise of the inference rule of $\parse {\LaA z M} {\Gamma} {(\LaO {\ve{\vec k}} t) }$} \\
% TODO how can I get ``multiline - mboxes''?
\prVal{x \sspace v_1 \sspace v_2 \sspace \ldots \sspace v_n} & = & x \ \prVal{v_1} \ \prVal{v_2} \ \ldots \ \prVal{v_n} \\
\medskip && \mbox{a large application simply becomes an application of terms} \\
\prVal{\Val {\vec k} t {\vec v}} & = & \pr{\LaO {\vec k} t}{\vec v} \\
\end{array}
\]
\end{defin}
First, note that the printing functions are well-defined (i.e. they always terminate). This is because during evaluation of $\pr{u}{\vec v}$, we may safely assume that $\pr{t}{\vec w}$ is well-defined as long as $t$ is a strict subterm of $u$ and each value $w'$ in $\vec w$ is either only a variable (so termination of $\prVal {w'}$ is clear) or also in $\vec v$. Similar, during evaluation of $\prVal {x \sspace v_1 \sspace \ldots v_n}$, we may assume that $\prVal {v_i}$ is defined for each $i$.

For all $t \in \otc, M \in \te$, we have $\pr t \emptyVec = M$ if and only if $\parse M \emptySet {t \emptyVec}$ as both judgements are defined identical in the case of closed ordered terms. This basically means $\prE \circ \parseFun \emptySet  = id_{\te}$, i.e. the composition of parsing and printing is the identity.


\section{Correctness and Completeness}


% TODO
We still have to prove several important facts about the evaluation algorithm given in section \ref{eval} - first, its termination properties and second, its correctness, i.e. it corresponds to beta reduction. 
%The problem of the latter is that, in fact, we do not even know the formal semantics of a value like $\Val {\vec k} t {\vec v}$ yet (although we have tried to give some intuition about it). To solve this, we define a printing function that transforms a value to a term in $\te$. We also need a function to transform an element of $\ot \otimes \vl$ into an element of $\te$ (note that the bijections above just provide such a translation for the subset $\ot \otimes \xl$).
%\begin{defin}
%We define the printing functions $\prE : \ot \otimes \vl \rightarrow \te / \alpha$ and $\prValE : \va \rightarrow \te / \alpha$ simultaneously by recursion on the structure:
%\[
%\begin{array}{lcl}
%\pr{x}{\emptyVec} & = & x \\
%\pr{\ovar}{[v]} & = & \prVal v \\
%% \pr{t \oapp k u}{\vec v} = \ApA {\pr {t}{[v_1, \ldots, v_k]}  }  {\pr {u}{[v_{k+1}, \ldots, v_n]}}
%\pr{t \oapp k u}{\vec v} & = & \ApA {\pr {t}{\vec{v_{start}}}  }  {\quad \pr {u}{\vec{v_{rest}}}} \\
%&& \mbox{(split $\vec v$ at position $k$ to get $\vec{v_{start}}$ and $\vec{v_{rest}}$)} \\
%% \pr{\LaO {k_1, \ldots, k_m} t}{[v_1, v_2, \ldots, v_n]} & = & \LaA z {\pr {t} {v_1, \ldots, v_{k_1}, z, v_{k_1+1}, \ldots, }}   \\
%\pr{\LaO {\vec k} t}{\vec v} & = & \LaA z {\pr {t} {  \multiinsert{\vec v}{\vec k}{z}   }}   \\
%\medskip
%&& \mbox{where $z$ is any variable that does not occur freely in $t$ or $\vec v$ } \\
%% && \mbox{$\vec w$ is constructed by taking $\vec v$ and inserting $z$ at position $k_1, k_1+k_2, \ldots$ just like} \\ 
%% && \mbox{in the premise of the inference rule of $\parse {\LaA z M} {\Gamma} {(\LaO {\ve{\vec k}} t) }$} \\
%% TODO how can I get ``multiline - mboxes''?
%\prVal{x \sspace v_1 \sspace v_2 \sspace \ldots \sspace v_n} & = & x \ \prVal{v_1} \ \prVal{v_2} \ \ldots \ \prVal{v_n} \\
%\medskip && \mbox{a large application simply becomes an application of terms} \\
%\prVal{\Val {\vec k} t {\vec v}} & = & \pr{\LaO {\vec k} t}{\vec v} \\
%\end{array}
%\]
%\end{defin}
%First, note that the printing functions are well-defined (i.e. they always terminate). This is because during evaluation of $\pr{u}{\vec v}$, we may safely assume that $\pr{t}{\vec w}$ is well-defined as long as $t$ is a strict subterm of $u$ and each value $w'$ in $\vec w$ is either only a variable (so termination of $\prVal {w'}$ is clear) or also in $\vec v$. Similar, during evaluation of $\prVal {x \sspace v_1 \sspace \ldots v_n}$, we may assume that $\prVal {v_i}$ is defined for each $i$.
%
%For all $t \in \otc, M \in \te$, we have $\pr t \emptyVec = M$ if and only if $\parse M \emptySet {t \emptyVec}$ as both judgements are defined identical in the case of closed ordered terms. This basically means $\prE \circ \parseFun \emptySet  = id_{\te}$, i.e. the composition of parsing and printing is the identity.

Concerning correctness, we would obviously want to show that taking a term $t$, translating it to an ordered term, evaluation and printing it gives us a term which is beta equal to $t$, which is represented by the diagram
\[
\begin{xy}
\xymatrix{
 t \in \te \ar@{-}[rrr]^{=_\beta} \ar@/_/[dd]_{\parseFun \emptySet} & & & t' \in \te \\ 
 \\
% u \in \otc \ar@/_/[uu]_{\pr{\cdot}{\emptyVec}} \ar[rrr]^{\ev{\cdot}{\emptyVec}} & & & \ev{u}{\emptyVec} \in \va \ar[uu]_{\prValE}
 u \in \otc \ar@/_/[uu]_{\prE                  } \ar[rrr]^{\ev{\cdot}{\emptyVec}} & & & \ev{u}{\emptyVec} \in \va \ar[uu]_{\prValE}
}
\end{xy}
\]
However, the diagram does not make much sense as we do not know yet that $\ev \cdot \emptyVec$ is a well-defined function.
What we need to do is to define a one-step-evaluation, thereby making it possible to check if each single evaluation step preserves beta equality. Unfortunately, this becomes even more complicated as we get binary trees during evaluation: 
\[
\begin{array}{lllrll@{\qquad}}
\evTr       & \ni & \mathsf{tree}_1, \mathsf{tree}_2 & ::= & (t, \vec v) & \mbox{a tupel in $\ot \otimes \vl$} \\
			                   &&& \mid & v & \mbox{just a value} \\
			                   &&& \mid & \tree {\mathsf{tree}_1} {\mathsf{tree}_2}  & \mbox{node with two subtrees} 
\end{array}
\]
Our one-step reduction $\osr$ is a relation on $\evTr \times \evTr$:

\begin{gather*}
\infnamed{^{\ev \cdot \cdot \mbox{-1} }}{}{(x , \emptyVec) \osr x}
\qquad
\qquad
\infnamed{^{\ev \cdot \cdot \mbox{-2}}}{}{(\ovar , \ve v) \osr v}
\qquad
\qquad
\infnamed{^{\ev \cdot \cdot \mbox{-3}}}{}{(t \oapp k u , \vec v \vec w) \osr \tree {(t, \vec v)}{(u, \vec w)}}
\\ \\
\infnamed{^{\ev \cdot \cdot \mbox{-4}}}{}{(\LaO {\vec k} t , \vec v) \osr \Val {\vec k} t {\vec v}}
\qquad
\qquad
\infnamed{^{\mbox{(struct-1)}}}{a \osr a'}{\tree a b \osr \tree {a'} b}
\qquad
\qquad
\infnamed{^{\mbox{(struct-2)}}}{b \osr b'}{\tree a b \osr \tree a {b'}}
\\ \\
\infnamed{^{@\mbox{-1}}}{}{\tree {x \sspace v_1 \ldots v_n} w \osr  x \sspace v_1 \ldots v_n \sspace w}
\qquad
\qquad
\infnamed{^{@\mbox{-2}}}{}{\tree {\Val {\vec k} t {\vec v}}{w}   \osr   (t, \multiinsert {\vec v} {\vec k} w)}
\end{gather*}
It is easy to convince oneself that, if $t \in \otc$ can be evaluated to a value using $\ev \cdot \emptyVec$, the one step evaluation above will provide the same result. 
Now it is easy to define a printing function $\prTreeE$ to transform a tree into a term:
\[
\begin{array}{lclll}
\prTree{(t, \vec v)} & = & \pr {t} {\vec v} &&\\
\prTree{v} & = & \prVal v &&\\
\prTree{\tree a b} & = & \ApA {\prTree a}{\prTree b}&& \mbox{(simply the application in $\te$)}
\end{array}
\]
\begin{prop}
 For $a, b \in \evTr$ satisfying $a \osr b$, we have $\prTree a =_\beta \prTree b$. More precisely, if one of the rules ${\ev \cdot \cdot \mbox{-1} }, {\ev \cdot \cdot \mbox{-2} }, {\ev \cdot \cdot \mbox{-3} }, {\ev \cdot \cdot \mbox{-4} }$ or ${@\mbox{-1}}$ was used, even $\prTree a = \prTree b$ (up to $\alpha$-equivalence) holds, if ${@\mbox{-1}}$ was used,  $\prTree a$ can be reduced to $\prTree b$ in exactly one $\beta$-reduction step.
\end{prop}
\begin{proof}
 For all of the $\ev \cdot \cdot$-rules, we even have the equality $\prTree a = \prTree b$. In the case of the structure rules, we may assume that the statement holds for the premises, so it is also clear for the conclusions. The first of the $@$-rules is also simple. We only have to have a closer look at the second $@$-rule.\\
 By definition, we have 
 \[
\begin{array}{lclr}
 \prTree {\tree {\Val {\vec k} t {\vec v}}{w}} & = & \ApA {  \prVal {\Val {\vec k} t {\vec v}}   } \ {\prVal w}  & \\
& = &\ApA {  \pr{\LaO {\vec k} t}{\vec v}   }  \ {\prVal w} \\
& = & \ApA {\left( \LaA z {\pr {t} {\multiinsert {\vec v}{\vec k}{z}}} \right)} \ {\prVal w} &  \qquad \mbox{$z$ not free in $t$, $\vec v$}\\
\mbox{and} &&& \\
 \prTree {    (t , \multiinsert{\vec v}{\vec k}{w} )    } & = & \pr{t}{\multiinsert{\vec v}{\vec k}{w}} &
\end{array}
\]
Now, note that (again by induction on $t$) the term $\pr {t} {\multiinsert {\vec v}{\vec k}{z}}$ contains  $z$ exactly $\length {\vec k}$ times as a free variable and, by replacing each of those free occurrences  by $\prVal w$, we get the term $\pr{t}{\multiinsert{\vec v}{\vec k}{w}}$.
Consequently, the term $\prTree {\tree {\Val {\vec k} t {\vec v}}{w}}$ can be reduced to $\prTree {    (t , \multiinsert{\vec v}{\vec k}{w} )    }$ in exactly one beta reduction step, thus the statement is true. 


\end{proof}

\begin{prop}
For any well-typed term $t \in \te$, the One-Step-Reduction terminates for $(\parseFunE t)$.
\end{prop}
\begin{proof}
Suppose there is an infinite sequence $a_0 \rightarrow a_1 \rightarrow a_2 \rightarrow \ldots$ with $a_0 = \parseFunE t$. According to the proposition above, we can conclude that for each $i$, either $\prTree {a_i} = \prTree {a_{i+1}}$ or $\prTree {a_i} \rightarrow_\beta \prTree {a_{i+1}}$ (in exactly one step). Assume the latter possibility occurres infinitely often. This contradicts the fact that $\beta$-reduction is strongly normalizing on well-types terms. Assume it occurs only finitely often. Then there is an $N$ such that $\prTree {a_N} = \prTree {a_{N+1}} = \prTree {a_{N+2}} = \ldots$. For $a \in \evTr$, we define the weight $w(a)$ as the number of leafs of $a$ containing an element of $\ot \otimes \vl$ plus twice the number of leafs that contain a value. Each of the one-step-rules except the last one (and the structure rules) obviously increases the weight of a tree, thus we get $w(a_N) < w(a_{N+1}) < w(a_{N+2}) < \ldots$. However, the printing function is defined in a way that forces the weight of any tree $a$ to be less or equal than twice the length of $a$ and consequently, the sequence above is bounded by $2 \cdot \length{ \prTree{a_N}}$, thus giving us a contradiction again.
\end{proof}
% TODO rename PARSINGfunction and make clear that sometimes parse: ... -> trees.

Note that if the reduction terminates, the result is a tree that consists of exactly one leaf containing a value (as there is a reduction step for any other case). We identify this tree with the value.

\begin{cor}
For all well-typed terms, the evaluation function $\ev \cdot \cdot$ is well-defined (i.e. terminates) and correct (i.e. parsing a term, evaluating and printing it results in a $\beta$-equivalent term).
\end{cor}
\begin{proof}
It is easy to check that the evaluation $\ev \cdot \cdot$ can be simulated by using a sequence of $\rightarrow$-steps. First, this shows that it terminates as we would get an infinite sequence of steps otherwise. Second, as each small step conserves $\beta$-equality, the whole sequence does the same. As we know that for $t \in \te$ the equality $\prTree {\parseFunE t , \emptyVec} = t$ holds, this implies $\prTree {\ev{\parseFunE t} {\emptyVec}} = t$. 
\end{proof}


\section{Experiments and Results}

The specified term representation and evaluation have been implemented in Haskell. Then, they have been used by a typechecker check dependently typed terms of the logical framework which were kindly provided by Andrew W. Appel (Princeton University). To make this possible, an extended syntax has been used that includes $\Pi$-types and technical elements like constants and definitions. It is easy to expand our evaluation algorithm to satisfy special needs like these.
\\
For comparison, the completely analogous algorithm for terms in extended basic syntax (i.e. $\te$) has been used.

Our main test file \textsf{w32\_sig\_semant.elf} with a size of approximately 21 megabytes contains a proof described in \cite{appel}. We also tested smaller parts of this file.
All tests were executed on the same server (``baerentatze'', Ludwig-Maximilians-Universit\"at M\"unchen, Department of Computer Science) working with a CPU of type \emph{AMD Phenom II X4 B95} (only one core used, 3000 MHz) and 7999 MiB system memory.

...etc...quite disappointing results...

\comment{
The results are a bit disappointing as they do not reveal real shortcomings of the algorithms. 
However, the following results for the complete file are remarkable. Here, implementing ordered substitutions as normal Haskell lists seems to be much more efficient than using tree structures

Below, the total used average processing time and memory are compared for the different evaluation strategies. In the case of the \emph{Ordered Representation}, we list the values for both the implementations of ordered substitutions as trees and as lists. Next come our \emph{Simple Closures} and finally the \emph{Beta Normal Values} which use hereditary substitution. The memory is only measured pointwise and therefore not completely accurate (which may explain why the stated total memory is, in one case, larger for a smaller file).

% rounded:
\begin{center}

\begin{tabular}{| l || c | c |}
\multicolumn{3}{c}{\textsf{6000.elf} (file size: 3.8 MB)}\\
\hline
& time (sec) & space (MB) \\
\hline
\hline
Ordered (trees) & 18.9 & 1111 \\
\hline
Ordered (lists) & 18.6 & 1114\\
\hline
Simple Closures & 18.5 & 1152\\
\hline
Beta Normal Values & 27.6 & 2034\\
\hline
\end{tabular}

\begin{tabular}{| l || c | c |}
\multicolumn{3}{c}{\textsf{10000.elf} (file size: 12.9 MB)}\\
\hline
& time (sec) & space (MB) \\
\hline
\hline
Ordered (trees) & 61.0 & 3230\\
\hline
Ordered (lists) & 60.6 & 3237\\
\hline
Simple Closures & 60.0 & 3302\\
\hline
Beta Normal Values & 98.7 & 5878\\
\hline
\end{tabular}

\begin{tabular}{| l || c | c |}
\multicolumn{3}{c}{\textsf{12000.elf} (file size: 17.8 MB)}\\
\hline
& time (sec) & space (MB) \\
\hline
\hline
Ordered (trees) & 84.3 & 5096 \\
\hline
Ordered (lists) & 83.8 & 5103 \\
\hline
Simple Closures & 83.6 & 5226 \\
\hline
Beta Normal Values & 137.7 & 8513 \\
\hline
\end{tabular}
\end{center}
Unsurprisingly, beta normal values perform significantly worse than each of the other possibilities. However, the difference is smaller than it could have been expected. This might be due to the fact that during typechecking, total evaluation of a term is often necessary anyway, thereby reducing the hereditary substitution's disadvantage. \\
None of the other strategies exhibited any shortcomings in the comparisons above. However, the following results for the complete file are remarkable. Here, implementing ordered substitutions as normal Haskell lists seems to be much more efficient than using tree structures: 
\begin{center}
 \begin{tabular}{| l || c | c |}
\multicolumn{3}{c}{\textsf{w32\_sig\_semant.elf} (file size: 20.9 MB)}\\
\hline
& time (sec) & space (MB) \\
\hline
\hline
Ordered (trees) & 108.4 & 8877\\
\hline
Ordered (lists) & 94.8 & 4948\\ % average, 4 values.
\hline
Simple Closures & 94.3 & 5068 \\ % some more tests: 92.42 , 4994 (?!); 94.17, 5068; 94.97, 5068; 93.75, 4994
\hline
Beta Normal Values & 169.8 & 9044  \\
\hline
\end{tabular}
\end{center}
Our Simple Closures are still on the same level as Ordered Representation with lists, but the trees are far behind. 
\\
In comparison, the typechecker of the Twelf project, \emph{Twelf r1697} (written in \emph{Standard ML}) does the job nearly five times faster with only 2720 megabytes of memory.

Unfortunately, the idea of ordered substitution lists does not really pay off within the context of typechecking in our tests. 
On the other hand, it can compete with the simple standard implementation. This offers hope that there might be some applications that benefit more from our suggested strategy. 
}


\section{Related Work}

\begin{thebibliography}{4} \addcontentsline{toc}{section}{References}
  
\bibitem{some more items}
  some name, some title, some journal
  
    
\bibitem{watkins}
  Kevin Watkins, Iliano Cervesato, Frank Pfenning, David Walker. \emph{A concurrent logical framework I: Judgements and properties}.\\
  % Technical Report, 
  School of Computer Science, Carnegie Mellon University, Pittsburgh, 2003.


\bibitem{appel} 
  Amal Ahmed, Andrew W. Appel, Christopher D. Richards, Kedar N. Swadi, Gang Tan, Daniel C. Wang. \emph{Semantic foundations for typed assembly languages}.\\
  ACM Trans. Program. Lang. Syst., volume 32, number 3, 2010.

\end{thebibliography}



%\comment{
%------------------ WRONG ------------------
%
%For all $t \in \otc, M \in \te$, we have $\pr t \emptyVec = M$ if and only if $\parse M \emptySet {t \emptyVec}$ as both judgements are defined identical in the case of closed ordered terms. This basically means $\prE \circ \parseFun \emptySet  = id_{\te}$, i.e. the composition of parsing and printing is the identity. This shows the first part of the following
%
%\begin{prop}
%For each $t \in \te$, $u = \parseFun \emptySet (t) \in \otc$, there exists a $t' \in \te$ such that the following diagram holds: % speaking about commutativtiy seems to make no sense here.
%\[
%\begin{xy}
%\xymatrix{
% t \in \te \ar@{-}[rrr]^{=_\beta} \ar@/_/[dd]_{\parseFun \emptySet} & & & t' \in \te \\ 
% \\
%% u \in \otc \ar@/_/[uu]_{\pr{\cdot}{\emptyVec}} \ar[rrr]^{\ev{\cdot}{\emptyVec}} & & & \ev{u}{\emptyVec} \in \va \ar[uu]_{\prValE}
% u \in \otc \ar@/_/[uu]_{\prE                  } \ar[rrr]^{\ev{\cdot}{\emptyVec}} & & & \ev{u}{\emptyVec} \in \va \ar[uu]_{\prValE}
%}
%\end{xy}
%\]
%\end{prop}
%\begin{proof}
%We prove the more general statement 
%\begin{center}\emph{for each $(t, \vec v) \in \ot \otimes \vl$, the equality $\pr t {\vec v} =_\beta \prVal {\ev t {\vec v}}$ holds}\end{center}
%\begin{center}\emph{and for $v, w \in \va$, we always have $\ApA {\prVal v}{\prVal w} =_\beta \prVal {v \ap w}$}\end{center}
%by induction: 
%% TODO the induction hypotheses is that if some term appears during the evaluation, the statements holds for this term. This works iff the evaluation function terminates! (okay, this is not always the case; assume `f(x) = snd(f(x), f(x-1))', which only works for lazy but not for applicative evaluation.)
%\renewcommand{\labelitemi}{$\diamond$}
%\begin{itemize}
%\item case $(x, \emptyVec)$. \lspace $\pr x \emptyVec = x = \prVal x = \prVal {\ev x \emptyVec}$. 
%\item case $(\ovar, [v])$. \lspace $\pr \ovar {[v]} = \prVal v = \prVal {\ev \ovar {[v]}}$. 
%\item case $(t \oapp k u, [\vec v, \vec w])$. \lspace $\pr {t \oapp k u} {[\vec v, \vec w]} = \ApA {\pr {t} {\vec v}}{\pr {u} {\vec w}} \stackrel{ind. hyp.}{=}{\ApA {\prVal{ \ev t {\vec v} }}{\prVal{ \ev u {\vec w} }}   } 
%\stackrel{ind. hyp.}= \prVal {\ev t {\vec v} \ap \ev u {\vec w}}$.
%\item case $\left( \LaO {\vec k} t , \vec v\right)$. \lspace $\pr {\LaO {\vec k} t} {\vec v} = \prVal {\Val {\vec k} t {\vec v}} = \prVal {\ev {\LaO {\vec k} t} {\vec v}}$
%\item case $(x \sspace v_1 \sspace v_2 \sspace \ldots \sspace v_n) \ap w$. \lspace $\prVal {(x \sspace v_1 \sspace v_2 \sspace \ldots \sspace v_n) \ap w} = \prVal {x \sspace v_1 \sspace v_2 \sspace \ldots \sspace v_n} \ \prVal w = \prVal {x \sspace v_1 \sspace v_2 \sspace \ldots \sspace v_n \sspace w}.$
%\item case $\Val {\vec k} t {\vec v}    \ap  w$. \lspace $\prVal {\Val {\vec k} t {\vec v}    \ap  w} 
%%ziel:
%= \ApA {\prVal{\Val {\vec k} t {\vec v}}} {\prVal{w}}$
%\end{itemize}
%
%\end{proof}
%}


\vspace{30pt}




% TODO decide: x or y = k ?!?
% TODO ordered application is sometimes invalid!
% TODO evaluation bleibt nicht stecken

\newpage 

---------------Gliederungsvorschlag---------------

\vspace{10pt}

1. Introduction (wie oben?) \\
2. Syntax angeben (wie oben?); Terme sind Preterme, in denen fuer alle Subterme $\LaO {\ve {k_1, \ldots k_n}} t$ die Ungleichung ``$n + \sum_{j} k_j \leq \mbox{Zahl der ungebundenen dots in $t$}$`` (letzteres spezifizieren) erfuellt ist \\
3. Werte spezifizieren \\
4. Auswertung spezifizieren. Beispiel angeben (eines?). \\
5. Parsing und Printing angeben. Zeigen, dass sie inverse Bijektionen zwischen (Terme in Standardsyntax modulo alpha) und (Terme in neuer Syntax vereinigt mit Werte in neuer Syntax) sind; das stimmt so aber gar nicht, es ist zwar ''Printing $\circ$ Parsing = id``, aber nicht andersrum, weil man aus Werten Terme macht; muss ich noch genauer machen, wird aber kein grosses Problem \\
Zeigen, dass jede Verknuepfung der Form (Printing $\circ$ Auswerten $\circ$ Parsing) sich auch durch Betareduktion in normaler Syntax erreichen laesst. Das heisst, man macht nichts falsches. Dann noch zeigen, dass (Printing $\circ$ AuswertenBisZumWert $\circ$ Parsing) tatsaechlich die Info liefert, die man haben will (''wie beginnt die Normalform des Terms``), d.h. man macht nicht zu wenig. \\
6. Experiment beschreiben, Ergebnisse praesentieren \\
7. Related work (dazu kann ich nichts schreiben) \\

Was meinst du? Wenn ich es so mache wie oben, wird das vermutlich zu lang, da muss ich mich wohl kuerzer fassen.

\end{document}
